{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Small1000_with_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>outlet</th>\n",
       "      <th>headline</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>authors</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>newsguard_score</th>\n",
       "      <th>extracted_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115898626</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>3 Men Decapitated, 2 More Slain in Acapulco Ov...</td>\n",
       "      <td>3 Men Decapitated, 2 More Slain in Acapulco Ov...</td>\n",
       "      <td>At least five people were killed over the New ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115884354</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Thousands in Hong Kong March for Pro-Democracy...</td>\n",
       "      <td>Thousands in Hong Kong March for Pro-Democracy...</td>\n",
       "      <td>Nearly 5,000 people in Hong Kong marched in a ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>115880292</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Slovakia Bans Train Patrols by Far-Right Party</td>\n",
       "      <td>Slovakia Bans Train Patrols by Far-Right Party</td>\n",
       "      <td>Train and railway station patrols set up by a ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>115985210</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Suicide Bombers Kill 9 South of Iraq's Capital</td>\n",
       "      <td>Suicide Bombers Kill 9 South of Iraq's Capital</td>\n",
       "      <td>Iraqi officials say a pair of suicide bombers ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>115912220</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Officials: Delaware Man Injured in Istanbul Ni...</td>\n",
       "      <td>Officials: Delaware Man Injured in Istanbul Ni...</td>\n",
       "      <td>The State Department has confirmed that a Dela...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/officials-d...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0         id         date_publish    outlet  \\\n",
       "0             0           0  115898626  2017-01-01 00:00:00  ABC_News   \n",
       "1             1           1  115884354  2017-01-01 00:00:00  ABC_News   \n",
       "2             2           2  115880292  2017-01-01 00:00:00  ABC_News   \n",
       "3             3           3  115985210  2017-01-01 00:00:00  ABC_News   \n",
       "4             4           4  115912220  2017-01-01 00:00:00  ABC_News   \n",
       "\n",
       "                                            headline  \\\n",
       "0  3 Men Decapitated, 2 More Slain in Acapulco Ov...   \n",
       "1  Thousands in Hong Kong March for Pro-Democracy...   \n",
       "2     Slovakia Bans Train Patrols by Far-Right Party   \n",
       "3     Suicide Bombers Kill 9 South of Iraq's Capital   \n",
       "4  Officials: Delaware Man Injured in Istanbul Ni...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  3 Men Decapitated, 2 More Slain in Acapulco Ov...   \n",
       "1  Thousands in Hong Kong March for Pro-Democracy...   \n",
       "2     Slovakia Bans Train Patrols by Far-Right Party   \n",
       "3     Suicide Bombers Kill 9 South of Iraq's Capital   \n",
       "4  Officials: Delaware Man Injured in Istanbul Ni...   \n",
       "\n",
       "                                                body       authors  \\\n",
       "0  At least five people were killed over the New ...  ['Abc News']   \n",
       "1  Nearly 5,000 people in Hong Kong marched in a ...  ['Abc News']   \n",
       "2  Train and railway station patrols set up by a ...  ['Abc News']   \n",
       "3  Iraqi officials say a pair of suicide bombers ...  ['Abc News']   \n",
       "4  The State Department has confirmed that a Dela...  ['Abc News']   \n",
       "\n",
       "           domain                                                url  \\\n",
       "0  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "1  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "2  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "3  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "4  abcnews.go.com  http://abcnews.go.com/US/wireStory/officials-d...   \n",
       "\n",
       "   political_leaning  newsguard_score extracted_names  \n",
       "0                  0             95.0              []  \n",
       "1                  0             95.0              []  \n",
       "2                  0             95.0              []  \n",
       "3                  0             95.0              []  \n",
       "4                  0             95.0              []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_text\"] = df[\"headline\"] + \" \" + df[\"lead\"] + \" \"+df[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/avsolatorio/GIST-small-Embedding-v0\n",
    "revision = None  # Replace with the specific revision to ensure reproducibility if the model is updated.\n",
    "\n",
    "model = SentenceTransformer(\"avsolatorio/GIST-small-Embedding-v0\", revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:350\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    347\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 350\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:355\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    352\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32mc:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"text_vectors\"] = df[\"combined_text\"].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date_publish</th>\n",
       "      <th>outlet</th>\n",
       "      <th>headline</th>\n",
       "      <th>lead</th>\n",
       "      <th>body</th>\n",
       "      <th>authors</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>political_leaning</th>\n",
       "      <th>newsguard_score</th>\n",
       "      <th>extracted_names</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>text_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115898626</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>3 Men Decapitated, 2 More Slain in Acapulco Ov...</td>\n",
       "      <td>3 Men Decapitated, 2 More Slain in Acapulco Ov...</td>\n",
       "      <td>At least five people were killed over the New ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>3 Men Decapitated, 2 More Slain in Acapulco Ov...</td>\n",
       "      <td>[0.014337818, -0.018631125, 0.030869678, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115884354</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Thousands in Hong Kong March for Pro-Democracy...</td>\n",
       "      <td>Thousands in Hong Kong March for Pro-Democracy...</td>\n",
       "      <td>Nearly 5,000 people in Hong Kong marched in a ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Thousands in Hong Kong March for Pro-Democracy...</td>\n",
       "      <td>[-0.06644088, 0.01585136, 0.011816703, -0.0274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>115880292</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Slovakia Bans Train Patrols by Far-Right Party</td>\n",
       "      <td>Slovakia Bans Train Patrols by Far-Right Party</td>\n",
       "      <td>Train and railway station patrols set up by a ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Slovakia Bans Train Patrols by Far-Right Party...</td>\n",
       "      <td>[-0.006447068, 0.039524555, -0.007932826, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>115985210</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Suicide Bombers Kill 9 South of Iraq's Capital</td>\n",
       "      <td>Suicide Bombers Kill 9 South of Iraq's Capital</td>\n",
       "      <td>Iraqi officials say a pair of suicide bombers ...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/International/wireStory/...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Suicide Bombers Kill 9 South of Iraq's Capital...</td>\n",
       "      <td>[0.011026992, 0.015652608, -0.04421485, -0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>115912220</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>ABC_News</td>\n",
       "      <td>Officials: Delaware Man Injured in Istanbul Ni...</td>\n",
       "      <td>Officials: Delaware Man Injured in Istanbul Ni...</td>\n",
       "      <td>The State Department has confirmed that a Dela...</td>\n",
       "      <td>['Abc News']</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/officials-d...</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Officials: Delaware Man Injured in Istanbul Ni...</td>\n",
       "      <td>[-0.016417947, 0.008195108, 0.02811521, -0.054...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0         id         date_publish    outlet  \\\n",
       "0             0           0  115898626  2017-01-01 00:00:00  ABC_News   \n",
       "1             1           1  115884354  2017-01-01 00:00:00  ABC_News   \n",
       "2             2           2  115880292  2017-01-01 00:00:00  ABC_News   \n",
       "3             3           3  115985210  2017-01-01 00:00:00  ABC_News   \n",
       "4             4           4  115912220  2017-01-01 00:00:00  ABC_News   \n",
       "\n",
       "                                            headline  \\\n",
       "0  3 Men Decapitated, 2 More Slain in Acapulco Ov...   \n",
       "1  Thousands in Hong Kong March for Pro-Democracy...   \n",
       "2     Slovakia Bans Train Patrols by Far-Right Party   \n",
       "3     Suicide Bombers Kill 9 South of Iraq's Capital   \n",
       "4  Officials: Delaware Man Injured in Istanbul Ni...   \n",
       "\n",
       "                                                lead  \\\n",
       "0  3 Men Decapitated, 2 More Slain in Acapulco Ov...   \n",
       "1  Thousands in Hong Kong March for Pro-Democracy...   \n",
       "2     Slovakia Bans Train Patrols by Far-Right Party   \n",
       "3     Suicide Bombers Kill 9 South of Iraq's Capital   \n",
       "4  Officials: Delaware Man Injured in Istanbul Ni...   \n",
       "\n",
       "                                                body       authors  \\\n",
       "0  At least five people were killed over the New ...  ['Abc News']   \n",
       "1  Nearly 5,000 people in Hong Kong marched in a ...  ['Abc News']   \n",
       "2  Train and railway station patrols set up by a ...  ['Abc News']   \n",
       "3  Iraqi officials say a pair of suicide bombers ...  ['Abc News']   \n",
       "4  The State Department has confirmed that a Dela...  ['Abc News']   \n",
       "\n",
       "           domain                                                url  \\\n",
       "0  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "1  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "2  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "3  abcnews.go.com  http://abcnews.go.com/International/wireStory/...   \n",
       "4  abcnews.go.com  http://abcnews.go.com/US/wireStory/officials-d...   \n",
       "\n",
       "   political_leaning  newsguard_score extracted_names  \\\n",
       "0                  0             95.0              []   \n",
       "1                  0             95.0              []   \n",
       "2                  0             95.0              []   \n",
       "3                  0             95.0              []   \n",
       "4                  0             95.0              []   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  3 Men Decapitated, 2 More Slain in Acapulco Ov...   \n",
       "1  Thousands in Hong Kong March for Pro-Democracy...   \n",
       "2  Slovakia Bans Train Patrols by Far-Right Party...   \n",
       "3  Suicide Bombers Kill 9 South of Iraq's Capital...   \n",
       "4  Officials: Delaware Man Injured in Istanbul Ni...   \n",
       "\n",
       "                                        text_vectors  \n",
       "0  [0.014337818, -0.018631125, 0.030869678, -0.00...  \n",
       "1  [-0.06644088, 0.01585136, 0.011816703, -0.0274...  \n",
       "2  [-0.006447068, 0.039524555, -0.007932826, -0.0...  \n",
       "3  [0.011026992, 0.015652608, -0.04421485, -0.022...  \n",
       "4  [-0.016417947, 0.008195108, 0.02811521, -0.054...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"id\",\"text_vectors\", \"political_leaning\"]].to_csv(\"text_vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"text_vectors.csv\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = pd.read_csv(\"node_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nodeLabel</th>\n",
       "      <th>embeddingVector</th>\n",
       "      <th>id</th>\n",
       "      <th>id1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[52898231]</td>\n",
       "      <td>[0.0035458847414702177, 0.0057817851193249226,...</td>\n",
       "      <td>52898231</td>\n",
       "      <td>[52898231]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[3239377]</td>\n",
       "      <td>[0.0035500838421285152, -0.002165608573704958,...</td>\n",
       "      <td>3239377</td>\n",
       "      <td>[3239377]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[52923954]</td>\n",
       "      <td>[0.003548684064298868, 0.0004835226573050022, ...</td>\n",
       "      <td>52923954</td>\n",
       "      <td>[52923954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[79068614]</td>\n",
       "      <td>[0.0035864762030541897, 0.007081980817019939, ...</td>\n",
       "      <td>79068614</td>\n",
       "      <td>[79068614]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[79069943]</td>\n",
       "      <td>[0.003589275758713484, 0.001783718355000019, 0...</td>\n",
       "      <td>79069943</td>\n",
       "      <td>[79069943]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   nodeLabel                                    embeddingVector  \\\n",
       "0           0  [52898231]  [0.0035458847414702177, 0.0057817851193249226,...   \n",
       "1           1   [3239377]  [0.0035500838421285152, -0.002165608573704958,...   \n",
       "2           2  [52923954]  [0.003548684064298868, 0.0004835226573050022, ...   \n",
       "3           3  [79068614]  [0.0035864762030541897, 0.007081980817019939, ...   \n",
       "4           5  [79069943]  [0.003589275758713484, 0.001783718355000019, 0...   \n",
       "\n",
       "         id         id1  \n",
       "0  52898231  [52898231]  \n",
       "1   3239377   [3239377]  \n",
       "2  52923954  [52923954]  \n",
       "3  79068614  [79068614]  \n",
       "4  79069943  [79069943]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes['id1'] = df_nodes[\"nodeLabel\"].apply(eval)\n",
    "df_nodes['id'] = df_nodes[\"id1\"].apply(lambda x:x[0])\n",
    "df_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.drop(columns=[\"nodeLabel\", \"Unnamed: 0\", 'id1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddingVector</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0035458847414702177, 0.0057817851193249226,...</td>\n",
       "      <td>52898231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0035500838421285152, -0.002165608573704958,...</td>\n",
       "      <td>3239377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.003548684064298868, 0.0004835226573050022, ...</td>\n",
       "      <td>52923954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0035864762030541897, 0.007081980817019939, ...</td>\n",
       "      <td>79068614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.003589275758713484, 0.001783718355000019, 0...</td>\n",
       "      <td>79069943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>[0.001482714549638331, 0.004351161886006594, 0...</td>\n",
       "      <td>3169220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>[0.0014757162425667048, 0.001971817808225751, ...</td>\n",
       "      <td>115972660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>[0.001474316231906414, 0.004620949272066355, -...</td>\n",
       "      <td>52987565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>[0.0014785154489800334, -0.0033264444209635258...</td>\n",
       "      <td>4487946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>[0.00147711590398103, -0.0006773132481612265, ...</td>\n",
       "      <td>4359729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       embeddingVector         id\n",
       "0    [0.0035458847414702177, 0.0057817851193249226,...   52898231\n",
       "1    [0.0035500838421285152, -0.002165608573704958,...    3239377\n",
       "2    [0.003548684064298868, 0.0004835226573050022, ...   52923954\n",
       "3    [0.0035864762030541897, 0.007081980817019939, ...   79068614\n",
       "4    [0.003589275758713484, 0.001783718355000019, 0...   79069943\n",
       "..                                                 ...        ...\n",
       "801  [0.001482714549638331, 0.004351161886006594, 0...    3169220\n",
       "802  [0.0014757162425667048, 0.001971817808225751, ...  115972660\n",
       "803  [0.001474316231906414, 0.004620949272066355, -...   52987565\n",
       "804  [0.0014785154489800334, -0.0033264444209635258...    4487946\n",
       "805  [0.00147711590398103, -0.0006773132481612265, ...    4359729\n",
       "\n",
       "[806 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_nodes.merge(df2[['id', 'text_vectors', 'political_leaning']], on= 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"node_text_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv(\"node_text_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>embeddingVector</th>\n",
       "      <th>id</th>\n",
       "      <th>text_vectors</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0035458847414702177, 0.0057817851193249226,...</td>\n",
       "      <td>52898231</td>\n",
       "      <td>[-0.03461906  0.03441137 -0.02845796 -0.030412...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0035500838421285152, -0.002165608573704958,...</td>\n",
       "      <td>3239377</td>\n",
       "      <td>[-1.17352558e-02  3.63212936e-02 -7.73911085e-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.003548684064298868, 0.0004835226573050022, ...</td>\n",
       "      <td>52923954</td>\n",
       "      <td>[ 7.41601037e-03  1.80580188e-02 -9.67473071e-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0035864762030541897, 0.007081980817019939, ...</td>\n",
       "      <td>79068614</td>\n",
       "      <td>[-0.03248248  0.03960977  0.04244677 -0.025196...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.003589275758713484, 0.001783718355000019, 0...</td>\n",
       "      <td>79069943</td>\n",
       "      <td>[-8.01296830e-02  2.70859562e-02 -1.30568352e-...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    embeddingVector        id  \\\n",
       "0           0  [0.0035458847414702177, 0.0057817851193249226,...  52898231   \n",
       "1           1  [0.0035500838421285152, -0.002165608573704958,...   3239377   \n",
       "2           2  [0.003548684064298868, 0.0004835226573050022, ...  52923954   \n",
       "3           3  [0.0035864762030541897, 0.007081980817019939, ...  79068614   \n",
       "4           4  [0.003589275758713484, 0.001783718355000019, 0...  79069943   \n",
       "\n",
       "                                        text_vectors  political_leaning  \n",
       "0  [-0.03461906  0.03441137 -0.02845796 -0.030412...                  1  \n",
       "1  [-1.17352558e-02  3.63212936e-02 -7.73911085e-...                  0  \n",
       "2  [ 7.41601037e-03  1.80580188e-02 -9.67473071e-...                  1  \n",
       "3  [-0.03248248  0.03960977  0.04244677 -0.025196...                  3  \n",
       "4  [-8.01296830e-02  2.70859562e-02 -1.30568352e-...                  3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings[\"embeddingVector\"] = df_embeddings[\"embeddingVector\"].apply(eval)\n",
    "df_embeddings[\"text_vectors\"] = df_embeddings[\"text_vectors\"].apply(lambda x: np.fromstring(x.strip('[]'), sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for i, r in df_embeddings.iterrows():\n",
    "    ans = np.concatenate([r[\"embeddingVector\"], r[\"text_vectors\"]])\n",
    "    final_list.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_list)\n",
    "# final_df = pd.DataFrame(df_embeddings[\"text_vectors\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"label\"] = df_embeddings[\"political_leaning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>-0.003112</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>-0.026761</td>\n",
       "      <td>-0.112526</td>\n",
       "      <td>-0.023985</td>\n",
       "      <td>0.046370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003550</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103092</td>\n",
       "      <td>-0.020565</td>\n",
       "      <td>-0.016281</td>\n",
       "      <td>-0.038384</td>\n",
       "      <td>0.055739</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.004868</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>-0.003627</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131135</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>0.043150</td>\n",
       "      <td>-0.022127</td>\n",
       "      <td>-0.019655</td>\n",
       "      <td>0.045448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>-0.006767</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>-0.003668</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049254</td>\n",
       "      <td>-0.027563</td>\n",
       "      <td>-0.033110</td>\n",
       "      <td>-0.005742</td>\n",
       "      <td>-0.052620</td>\n",
       "      <td>-0.042160</td>\n",
       "      <td>-0.055521</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>-0.015511</td>\n",
       "      <td>-0.016754</td>\n",
       "      <td>-0.039646</td>\n",
       "      <td>-0.046505</td>\n",
       "      <td>-0.072758</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.003546  0.005782 -0.003112  0.003954 -0.003797  0.001776 -0.001275   \n",
       "1  0.003550 -0.002166  0.001405 -0.001466 -0.005525  0.001484  0.002857   \n",
       "2  0.003549  0.000484 -0.005309 -0.004868  0.000259 -0.003627 -0.003729   \n",
       "3  0.003586  0.007082  0.004097 -0.006767  0.000327 -0.006256  0.002210   \n",
       "4  0.003589  0.001784  0.001900  0.000037  0.004383  0.003966 -0.000244   \n",
       "\n",
       "          7         8         9  ...       439       440       441       442  \\\n",
       "0  0.007202  0.006871  0.003965  ... -0.014324 -0.034225  0.035101  0.001452   \n",
       "1 -0.006315  0.003683  0.004160  ... -0.103092 -0.020565 -0.016281 -0.038384   \n",
       "2 -0.007018  0.004746  0.004095  ... -0.131135 -0.006244  0.007249  0.009222   \n",
       "3 -0.003668  0.007303  0.005853  ... -0.049254 -0.027563 -0.033110 -0.005742   \n",
       "4 -0.002263  0.005177  0.005983  ...  0.026949  0.034450 -0.015511 -0.016754   \n",
       "\n",
       "        443       444       445       446       447  label  \n",
       "0 -0.000742 -0.026761 -0.112526 -0.023985  0.046370      1  \n",
       "1  0.055739  0.013527 -0.000829  0.035034  0.057270      0  \n",
       "2 -0.001193  0.043150 -0.022127 -0.019655  0.045448      1  \n",
       "3 -0.052620 -0.042160 -0.055521  0.031746  0.020767      3  \n",
       "4 -0.039646 -0.046505 -0.072758  0.011584  0.074044      3  \n",
       "\n",
       "[5 rows x 449 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Node_text_viz.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['label'])\n",
    "y = final_df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4931129476584022\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model= RandomForestClassifier()\n",
    "model = SVC(C=1,kernel=\"rbf\",gamma=\"scale\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\majal\\Desktop\\GP2\\Bias-lensGP2\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 3s - 281ms/step - accuracy: 0.3268 - loss: 1.3609 - val_accuracy: 0.4615 - val_loss: 1.4011\n",
      "Epoch 2/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4086 - loss: 1.2840 - val_accuracy: 0.4615 - val_loss: 1.4381\n",
      "Epoch 3/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4241 - loss: 1.2247 - val_accuracy: 0.4615 - val_loss: 1.5012\n",
      "Epoch 4/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4241 - loss: 1.2808 - val_accuracy: 0.4615 - val_loss: 1.5099\n",
      "Epoch 5/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4241 - loss: 1.3896 - val_accuracy: 0.4615 - val_loss: 1.4734\n",
      "Epoch 6/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4241 - loss: 1.2439 - val_accuracy: 0.4615 - val_loss: 1.4507\n",
      "Epoch 7/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4241 - loss: 1.2417 - val_accuracy: 0.4615 - val_loss: 1.4825\n",
      "Epoch 8/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4202 - loss: 1.2997 - val_accuracy: 0.4615 - val_loss: 1.5003\n",
      "Epoch 9/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4358 - loss: 1.2010 - val_accuracy: 0.4615 - val_loss: 1.4515\n",
      "Epoch 10/100\n",
      "9/9 - 0s - 14ms/step - accuracy: 0.4319 - loss: 1.2099 - val_accuracy: 0.4615 - val_loss: 1.4489\n",
      "Epoch 11/100\n",
      "9/9 - 0s - 14ms/step - accuracy: 0.4241 - loss: 1.0956 - val_accuracy: 0.4615 - val_loss: 1.5066\n",
      "Epoch 12/100\n",
      "9/9 - 0s - 13ms/step - accuracy: 0.4241 - loss: 1.1952 - val_accuracy: 0.4615 - val_loss: 1.4578\n",
      "Epoch 13/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4319 - loss: 0.9937 - val_accuracy: 0.5077 - val_loss: 1.3384\n",
      "Epoch 14/100\n",
      "9/9 - 0s - 15ms/step - accuracy: 0.4202 - loss: 1.1658 - val_accuracy: 0.5231 - val_loss: 1.3839\n",
      "Epoch 15/100\n",
      "9/9 - 0s - 14ms/step - accuracy: 0.4358 - loss: 0.9570 - val_accuracy: 0.5077 - val_loss: 1.4382\n",
      "Epoch 16/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4475 - loss: 1.0590 - val_accuracy: 0.4769 - val_loss: 1.3809\n",
      "Epoch 17/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.4747 - loss: 1.1280 - val_accuracy: 0.4769 - val_loss: 1.4103\n",
      "Epoch 18/100\n",
      "9/9 - 0s - 13ms/step - accuracy: 0.4864 - loss: 1.0320 - val_accuracy: 0.4769 - val_loss: 1.4966\n",
      "Epoch 19/100\n",
      "9/9 - 0s - 14ms/step - accuracy: 0.4630 - loss: 1.0698 - val_accuracy: 0.5077 - val_loss: 1.4563\n",
      "Epoch 20/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.5058 - loss: 0.9443 - val_accuracy: 0.4923 - val_loss: 1.4636\n",
      "Epoch 21/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.4942 - loss: 0.9169 - val_accuracy: 0.5077 - val_loss: 1.7104\n",
      "Epoch 22/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.5331 - loss: 1.0380 - val_accuracy: 0.4769 - val_loss: 1.3356\n",
      "Epoch 23/100\n",
      "9/9 - 0s - 13ms/step - accuracy: 0.5370 - loss: 0.8565 - val_accuracy: 0.4462 - val_loss: 1.4579\n",
      "Epoch 24/100\n",
      "9/9 - 0s - 13ms/step - accuracy: 0.5642 - loss: 1.0627 - val_accuracy: 0.4769 - val_loss: 1.3630\n",
      "Epoch 25/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6031 - loss: 1.0326 - val_accuracy: 0.4615 - val_loss: 1.5076\n",
      "Epoch 26/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.5875 - loss: 0.9884 - val_accuracy: 0.5077 - val_loss: 1.6208\n",
      "Epoch 27/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6381 - loss: 0.8337 - val_accuracy: 0.4923 - val_loss: 1.4202\n",
      "Epoch 28/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.6031 - loss: 1.1641 - val_accuracy: 0.5077 - val_loss: 1.5516\n",
      "Epoch 29/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6226 - loss: 1.0579 - val_accuracy: 0.4000 - val_loss: 1.3976\n",
      "Epoch 30/100\n",
      "9/9 - 0s - 15ms/step - accuracy: 0.5837 - loss: 0.9791 - val_accuracy: 0.5231 - val_loss: 2.4259\n",
      "Epoch 31/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6070 - loss: 0.8595 - val_accuracy: 0.4154 - val_loss: 1.6431\n",
      "Epoch 32/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6187 - loss: 0.9412 - val_accuracy: 0.5077 - val_loss: 2.3591\n",
      "Epoch 33/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.6148 - loss: 1.1012 - val_accuracy: 0.4308 - val_loss: 1.6356\n",
      "Epoch 34/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6420 - loss: 0.8716 - val_accuracy: 0.3692 - val_loss: 1.3695\n",
      "Epoch 35/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.6498 - loss: 0.9853 - val_accuracy: 0.4923 - val_loss: 1.5277\n",
      "Epoch 36/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6070 - loss: 0.8847 - val_accuracy: 0.3846 - val_loss: 1.4373\n",
      "Epoch 37/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6148 - loss: 0.7707 - val_accuracy: 0.4000 - val_loss: 1.5811\n",
      "Epoch 38/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.5992 - loss: 0.8728 - val_accuracy: 0.4615 - val_loss: 2.0058\n",
      "Epoch 39/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6342 - loss: 0.9492 - val_accuracy: 0.3846 - val_loss: 1.5596\n",
      "Epoch 40/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7121 - loss: 0.7701 - val_accuracy: 0.5231 - val_loss: 2.2356\n",
      "Epoch 41/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.6615 - loss: 0.8421 - val_accuracy: 0.4462 - val_loss: 1.4925\n",
      "Epoch 42/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.6809 - loss: 0.7563 - val_accuracy: 0.4923 - val_loss: 1.5958\n",
      "Epoch 43/100\n",
      "9/9 - 0s - 15ms/step - accuracy: 0.6459 - loss: 0.7575 - val_accuracy: 0.5077 - val_loss: 1.8307\n",
      "Epoch 44/100\n",
      "9/9 - 0s - 9ms/step - accuracy: 0.7043 - loss: 0.8137 - val_accuracy: 0.4462 - val_loss: 1.5727\n",
      "Epoch 45/100\n",
      "9/9 - 0s - 10ms/step - accuracy: 0.7121 - loss: 0.6296 - val_accuracy: 0.5231 - val_loss: 1.7616\n",
      "Epoch 46/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7004 - loss: 0.8096 - val_accuracy: 0.4308 - val_loss: 1.5881\n",
      "Epoch 47/100\n",
      "9/9 - 0s - 10ms/step - accuracy: 0.6926 - loss: 0.6321 - val_accuracy: 0.4769 - val_loss: 1.7945\n",
      "Epoch 48/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7121 - loss: 0.6108 - val_accuracy: 0.5077 - val_loss: 1.7179\n",
      "Epoch 49/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7782 - loss: 0.6574 - val_accuracy: 0.4923 - val_loss: 1.6866\n",
      "Epoch 50/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7471 - loss: 0.7676 - val_accuracy: 0.4308 - val_loss: 1.7492\n",
      "Epoch 51/100\n",
      "9/9 - 0s - 15ms/step - accuracy: 0.7393 - loss: 0.6584 - val_accuracy: 0.4462 - val_loss: 1.6922\n",
      "Epoch 52/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7510 - loss: 0.5758 - val_accuracy: 0.4923 - val_loss: 1.7277\n",
      "Epoch 53/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7471 - loss: 0.5243 - val_accuracy: 0.4769 - val_loss: 1.6926\n",
      "Epoch 54/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7938 - loss: 0.5821 - val_accuracy: 0.4462 - val_loss: 1.7822\n",
      "Epoch 55/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7938 - loss: 0.4906 - val_accuracy: 0.4923 - val_loss: 1.9850\n",
      "Epoch 56/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7899 - loss: 0.5566 - val_accuracy: 0.4769 - val_loss: 1.9940\n",
      "Epoch 57/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7626 - loss: 0.5021 - val_accuracy: 0.5231 - val_loss: 2.5946\n",
      "Epoch 58/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8249 - loss: 0.4907 - val_accuracy: 0.4769 - val_loss: 2.4938\n",
      "Epoch 59/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7782 - loss: 0.4710 - val_accuracy: 0.4923 - val_loss: 2.8001\n",
      "Epoch 60/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7704 - loss: 0.5167 - val_accuracy: 0.4308 - val_loss: 1.9932\n",
      "Epoch 61/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7899 - loss: 0.4642 - val_accuracy: 0.4308 - val_loss: 1.7964\n",
      "Epoch 62/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8132 - loss: 0.5267 - val_accuracy: 0.4462 - val_loss: 2.2078\n",
      "Epoch 63/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8093 - loss: 0.4185 - val_accuracy: 0.4308 - val_loss: 2.4882\n",
      "Epoch 64/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8016 - loss: 0.4275 - val_accuracy: 0.4923 - val_loss: 2.1222\n",
      "Epoch 65/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8171 - loss: 0.5324 - val_accuracy: 0.5231 - val_loss: 2.5473\n",
      "Epoch 66/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.7626 - loss: 0.5029 - val_accuracy: 0.4923 - val_loss: 1.9654\n",
      "Epoch 67/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.7938 - loss: 0.5437 - val_accuracy: 0.4923 - val_loss: 1.7564\n",
      "Epoch 68/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8016 - loss: 0.4537 - val_accuracy: 0.4462 - val_loss: 2.1155\n",
      "Epoch 69/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8016 - loss: 0.4278 - val_accuracy: 0.4769 - val_loss: 2.3210\n",
      "Epoch 70/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8132 - loss: 0.3910 - val_accuracy: 0.4615 - val_loss: 2.1668\n",
      "Epoch 71/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8093 - loss: 0.4266 - val_accuracy: 0.4615 - val_loss: 2.0740\n",
      "Epoch 72/100\n",
      "9/9 - 0s - 14ms/step - accuracy: 0.8599 - loss: 0.3565 - val_accuracy: 0.5077 - val_loss: 2.2001\n",
      "Epoch 73/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8210 - loss: 0.3727 - val_accuracy: 0.5077 - val_loss: 2.1673\n",
      "Epoch 74/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8872 - loss: 0.2854 - val_accuracy: 0.5077 - val_loss: 2.8850\n",
      "Epoch 75/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8366 - loss: 0.3662 - val_accuracy: 0.4615 - val_loss: 2.2499\n",
      "Epoch 76/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8872 - loss: 0.5154 - val_accuracy: 0.4769 - val_loss: 2.7562\n",
      "Epoch 77/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8016 - loss: 0.5420 - val_accuracy: 0.4769 - val_loss: 2.4819\n",
      "Epoch 78/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8444 - loss: 0.4329 - val_accuracy: 0.4154 - val_loss: 1.9365\n",
      "Epoch 79/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8054 - loss: 0.4169 - val_accuracy: 0.4462 - val_loss: 1.8540\n",
      "Epoch 80/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8833 - loss: 0.3287 - val_accuracy: 0.4615 - val_loss: 2.0396\n",
      "Epoch 81/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8872 - loss: 0.4449 - val_accuracy: 0.4769 - val_loss: 2.0983\n",
      "Epoch 82/100\n",
      "9/9 - 0s - 10ms/step - accuracy: 0.8716 - loss: 0.3305 - val_accuracy: 0.5077 - val_loss: 1.9042\n",
      "Epoch 83/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8560 - loss: 0.3755 - val_accuracy: 0.4923 - val_loss: 2.1079\n",
      "Epoch 84/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8911 - loss: 0.2864 - val_accuracy: 0.4923 - val_loss: 2.0761\n",
      "Epoch 85/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8638 - loss: 0.3770 - val_accuracy: 0.4923 - val_loss: 2.2895\n",
      "Epoch 86/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8755 - loss: 0.3473 - val_accuracy: 0.4769 - val_loss: 3.0128\n",
      "Epoch 87/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8560 - loss: 0.7327 - val_accuracy: 0.4769 - val_loss: 3.3199\n",
      "Epoch 88/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8949 - loss: 0.2857 - val_accuracy: 0.4923 - val_loss: 3.3037\n",
      "Epoch 89/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8366 - loss: 0.4356 - val_accuracy: 0.4308 - val_loss: 2.8048\n",
      "Epoch 90/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.9027 - loss: 0.3015 - val_accuracy: 0.4462 - val_loss: 2.5757\n",
      "Epoch 91/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8833 - loss: 0.2591 - val_accuracy: 0.4769 - val_loss: 3.9164\n",
      "Epoch 92/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.8638 - loss: 0.3009 - val_accuracy: 0.4615 - val_loss: 3.1848\n",
      "Epoch 93/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8872 - loss: 0.2728 - val_accuracy: 0.4769 - val_loss: 3.4505\n",
      "Epoch 94/100\n",
      "9/9 - 0s - 10ms/step - accuracy: 0.8988 - loss: 0.2638 - val_accuracy: 0.4462 - val_loss: 2.6947\n",
      "Epoch 95/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8755 - loss: 0.2916 - val_accuracy: 0.4308 - val_loss: 3.3308\n",
      "Epoch 96/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8677 - loss: 0.3039 - val_accuracy: 0.4308 - val_loss: 3.8415\n",
      "Epoch 97/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.9027 - loss: 0.3122 - val_accuracy: 0.4615 - val_loss: 3.3343\n",
      "Epoch 98/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.9066 - loss: 0.2277 - val_accuracy: 0.4923 - val_loss: 3.6420\n",
      "Epoch 99/100\n",
      "9/9 - 0s - 11ms/step - accuracy: 0.8794 - loss: 0.2842 - val_accuracy: 0.4923 - val_loss: 4.2032\n",
      "Epoch 100/100\n",
      "9/9 - 0s - 12ms/step - accuracy: 0.9300 - loss: 0.2199 - val_accuracy: 0.4769 - val_loss: 4.3560\n",
      "16/16 - 0s - 3ms/step - accuracy: 0.4835 - loss: 3.1677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4834710657596588"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1dad78fef90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
